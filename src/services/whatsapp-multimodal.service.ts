import { MultiModalHelpers } from './multimodal-helpers.service'
import { MultiModalContent, MultiModalAnalysis, MultiModalIntentResult } from '../types/multimodal.types'
import { ConversationContext, Intent } from '../types/ai.types'
import { AdvancedIntentRecognitionService } from './advanced-intent-recognition.service'
import mime from 'mime-types'

/**
 * Extens√£o do WhatsApp Service para suporte multi-modal
 */
export class WhatsAppMultiModalService {
  private helpers: MultiModalHelpers
  private intentService: AdvancedIntentRecognitionService

  constructor() {
    this.helpers = new MultiModalHelpers()
    this.intentService = new AdvancedIntentRecognitionService()
  }

  /**
   * Processar mensagem multi-modal do WhatsApp
   */
  async processMultiModalMessage(
    textMessage: string,
    mediaFiles: Array<{
      buffer: Buffer
      filename?: string
      mimetype: string
    }>,
    context: ConversationContext
  ): Promise<MultiModalIntentResult> {
    
    console.log(`üîÑ Processando mensagem multi-modal: texto + ${mediaFiles.length} arquivos`)

    // 1. Processar intent do texto primeiro
    const textIntent = await this.intentService.recognizeIntent(textMessage, context)
    console.log(`üìù Intent do texto: ${textIntent.type} (${(textIntent.confidence * 100).toFixed(1)}%)`)

    // 2. Processar arquivos de m√≠dia
    const multiModalContent: MultiModalContent[] = []
    
    for (let i = 0; i < mediaFiles.length; i++) {
      const file = mediaFiles[i]!
      
      const content: MultiModalContent = {
        id: `media_${Date.now()}_${i}`,
        type: this.determineContentType(file.mimetype),
        content: file.buffer,
        mimeType: file.mimetype,
        filename: file.filename,
        metadata: {
          size: file.buffer.length
        },
        timestamp: new Date()
      }
      
      multiModalContent.push(content)
      console.log(`üìé Adicionado: ${content.type} (${this.formatFileSize(content.metadata?.size || 0)})`)
    }

    // 3. Processar cada conte√∫do multi-modal
    const analyses: MultiModalAnalysis[] = []
    
    for (const content of multiModalContent) {
      try {
        let analysis: MultiModalAnalysis
        
        switch (content.type) {
          case 'audio':
            analysis = await this.processAudio(content)
            break
          case 'image':
            analysis = await this.processImage(content)
            break
          case 'document':
            analysis = await this.processDocument(content)
            break
          case 'video':
            analysis = await this.processVideo(content)
            break
          default:
            analysis = await this.processGeneric(content)
        }
        
        analyses.push(analysis)
        console.log(`‚úÖ ${content.type} processado: confian√ßa ${(analysis.confidence * 100).toFixed(1)}%`)
        
      } catch (error) {
        console.error(`‚ùå Erro processando ${content.type}:`, error)
        
        // Criar an√°lise de fallback
        const fallbackAnalysis: MultiModalAnalysis = {
          contentId: content.id,
          contentType: content.type,
          primaryAnalysis: `Erro ao processar ${content.type}: ${error}`,
          entities: [],
          confidence: 0.3,
          processingTime: 0,
          warnings: [`Falha no processamento: ${error}`]
        }
        
        analyses.push(fallbackAnalysis)
      }
    }

    // 4. Combinar an√°lises e gerar resultado final
    const result = await this.combineAnalyses(textIntent, analyses, context)
    
    console.log(`üéØ Resultado final: ${result.recommendedAction} (confian√ßa: ${(result.confidence * 100).toFixed(1)}%)`)
    console.log(`üë• Requer humano: ${result.requiresHumanReview ? 'Sim' : 'N√£o'}`)
    
    return result
  }

  /**
   * Processar mensagem apenas com texto
   */
  async processTextOnlyMessage(
    textMessage: string,
    context: ConversationContext
  ): Promise<Intent> {
    return await this.intentService.recognizeIntent(textMessage, context)
  }

  /**
   * Validar arquivo de m√≠dia
   */
  validateMediaFile(buffer: Buffer, mimetype: string): { isValid: boolean; error?: string } {
    const capabilities = this.getCapabilities()
    const contentType = this.determineContentType(mimetype)
    
    // Verificar se o tipo √© suportado
    const supportedFormats = capabilities.supportedFormats[contentType as keyof typeof capabilities.supportedFormats]
    
    if (!supportedFormats || !supportedFormats.includes(mimetype)) {
      return {
        isValid: false,
        error: `Tipo de arquivo n√£o suportado: ${mimetype}`
      }
    }
    
    // Verificar tamanho do arquivo
    const maxSize = capabilities.maxFileSize[contentType as keyof typeof capabilities.maxFileSize]
    
    if (buffer.length > maxSize) {
      return {
        isValid: false,
        error: `Arquivo muito grande: ${this.formatFileSize(buffer.length)} (m√°ximo: ${this.formatFileSize(maxSize)})`
      }
    }
    
    return { isValid: true }
  }

  /**
   * Obter capacidades do sistema
   */
  getCapabilities() {
    return {
      supportedFormats: {
        audio: ['audio/wav', 'audio/mp3', 'audio/m4a', 'audio/ogg', 'audio/mpeg'],
        image: ['image/jpeg', 'image/png', 'image/gif', 'image/webp', 'image/jpg'],
        video: ['video/mp4', 'video/mov', 'video/avi', 'video/quicktime'],
        document: ['application/pdf', 'text/plain', 'application/msword', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document']
      },
      maxFileSize: {
        audio: 25 * 1024 * 1024, // 25MB
        image: 20 * 1024 * 1024,  // 20MB
        video: 100 * 1024 * 1024, // 100MB
        document: 50 * 1024 * 1024 // 50MB
      }
    }
  }

  /**
   * Gerar resposta contextual baseada na an√°lise
   */
  generateContextualResponse(result: MultiModalIntentResult): string {
    const { originalIntent, multiModalEnhancement, recommendedAction, requiresHumanReview } = result
    
    // Mensagens base por tipo de intent
    const baseResponses = {
      booking_request: 'Entendi que voc√™ gostaria de agendar um servi√ßo.',
      booking_cancel: 'Vou ajudar voc√™ a cancelar seu agendamento.',
      service_inquiry: 'Vou fornecer informa√ß√µes sobre nossos servi√ßos.',
      emergency: 'Entendo que √© uma situa√ß√£o urgente.',
      greeting: 'Ol√°! Como posso ajudar voc√™ hoje?',
      complaint: 'Lamento pelo inconveniente. Vamos resolver isso.',
      compliment: 'Muito obrigado pelo feedback positivo!',
      price_inquiry: 'Vou informar os pre√ßos dos nossos servi√ßos.',
      availability_check: 'Vou verificar nossa disponibilidade.',
      support_request: 'Estou aqui para ajudar voc√™.',
      goodbye: 'Obrigado pelo contato! At√© logo!',
      unknown: 'Vou analisar sua solicita√ß√£o.'
    }

    let response = baseResponses[originalIntent.type as keyof typeof baseResponses] || baseResponses.unknown

    // Adicionar informa√ß√µes sobre m√≠dia processada
    if (multiModalEnhancement.contentType !== 'text') {
      const mediaTypes = {
        audio: '√°udio',
        image: 'imagem',
        video: 'v√≠deo',
        document: 'documento'
      }
      
      const mediaType = mediaTypes[multiModalEnhancement.contentType as keyof typeof mediaTypes]
      response += ` Analisei tamb√©m o ${mediaType} que voc√™ enviou.`
    }

    // Adicionar informa√ß√µes sobre emo√ß√£o detectada
    if (multiModalEnhancement.emotionalAnalysis) {
      const emotion = multiModalEnhancement.emotionalAnalysis
      if (emotion.tone === 'frustrated' || emotion.tone === 'negative') {
        response += ' Percebo que voc√™ pode estar preocupado, vou dar aten√ß√£o especial ao seu caso.'
      } else if (emotion.tone === 'positive' || emotion.tone === 'excited') {
        response += ' Fico feliz em perceber seu entusiasmo!'
      }
    }

    // Adicionar a√ß√£o recomendada
    switch (recommendedAction) {
      case 'escalate_to_human':
        response += ' Vou conectar voc√™ com um de nossos especialistas para melhor atendimento.'
        break
      case 'create_appointment':
        response += ' Vou ajudar voc√™ a agendar um hor√°rio.'
        break
      case 'emergency_response':
        response += ' Trataremos isso como prioridade m√°xima.'
        break
      case 'human_review':
        response += ' Nossa equipe revisar√° sua solicita√ß√£o pessoalmente.'
        break
    }

    return response
  }

  // M√©todos privados de processamento

  private async processAudio(content: MultiModalContent): Promise<MultiModalAnalysis> {
    console.log('üéµ Processando √°udio...')
    
    const transcription = await this.helpers.transcribeAudio(
      content.content as Buffer, 
      content.mimeType
    )
    
    if (transcription.includes('[√Åudio recebido')) {
      return {
        contentId: content.id,
        contentType: 'audio',
        primaryAnalysis: transcription,
        transcription,
        entities: [],
        confidence: 0.6,
        processingTime: 0,
        businessContext: {
          relevantServices: [],
          suggestedActions: ['human_review'],
          urgencyLevel: 'medium',
          requiresHumanReview: true,
          contextualInsights: ['√Åudio requer an√°lise manual']
        }
      }
    }

    // An√°lise completa do √°udio transcrito
    const [entities, businessContext, emotionalAnalysis] = await Promise.all([
      this.helpers.extractEntitiesFromText(transcription),
      this.helpers.analyzeTextForBusiness(transcription),
      this.helpers.analyzeTextEmotion(transcription)
    ])

    return {
      contentId: content.id,
      contentType: 'audio',
      primaryAnalysis: transcription,
      transcription,
      entities,
      businessContext,
      emotionalAnalysis,
      confidence: 0.85,
      processingTime: 0
    }
  }

  private async processImage(content: MultiModalContent): Promise<MultiModalAnalysis> {
    console.log('üñºÔ∏è Processando imagem...')
    
    const [visualDescription, ocrText] = await Promise.all([
      this.helpers.analyzeImageVisually(content.content as Buffer, content.mimeType),
      this.helpers.extractTextFromImage(content.content as Buffer, content.mimeType)
    ])

    const combinedText = `${visualDescription} ${ocrText}`.trim()
    
    const [entities, businessContext, emotionalAnalysis] = await Promise.all([
      this.helpers.extractEntitiesFromText(combinedText),
      this.helpers.analyzeTextForBusiness(combinedText),
      this.helpers.analyzeTextEmotion(combinedText)
    ])

    return {
      contentId: content.id,
      contentType: 'image',
      primaryAnalysis: visualDescription,
      visualDescription,
      ocrText,
      entities,
      businessContext,
      emotionalAnalysis,
      confidence: 0.80,
      processingTime: 0
    }
  }

  private async processDocument(content: MultiModalContent): Promise<MultiModalAnalysis> {
    console.log('üìÑ Processando documento...')
    
    const extractedText = await this.helpers.extractTextFromDocument(
      content.content as Buffer, 
      content.mimeType
    )

    const [entities, businessContext, emotionalAnalysis] = await Promise.all([
      this.helpers.extractEntitiesFromText(extractedText),
      this.helpers.analyzeDocumentForBusiness(extractedText, content.mimeType),
      this.helpers.analyzeTextEmotion(extractedText)
    ])

    return {
      contentId: content.id,
      contentType: 'document',
      primaryAnalysis: extractedText,
      ocrText: extractedText,
      entities,
      businessContext,
      emotionalAnalysis,
      confidence: 0.90,
      processingTime: 0
    }
  }

  private async processVideo(content: MultiModalContent): Promise<MultiModalAnalysis> {
    console.log('üé• Processando v√≠deo...')
    
    // An√°lise b√°sica de v√≠deo (expandir conforme necess√°rio)
    const basicAnalysis = `V√≠deo recebido (${content.mimeType}, ${this.formatFileSize(content.metadata!.size)})`

    return {
      contentId: content.id,
      contentType: 'video',
      primaryAnalysis: basicAnalysis,
      entities: [],
      confidence: 0.70,
      processingTime: 0,
      businessContext: {
        relevantServices: [],
        suggestedActions: ['human_review'],
        urgencyLevel: 'medium',
        requiresHumanReview: true,
        contextualInsights: ['V√≠deo requer an√°lise manual']
      }
    }
  }

  private async processGeneric(content: MultiModalContent): Promise<MultiModalAnalysis> {
    console.log('üìé Processando arquivo gen√©rico...')
    
    return {
      contentId: content.id,
      contentType: content.type,
      primaryAnalysis: `Arquivo ${content.type} recebido`,
      entities: [],
      confidence: 0.50,
      processingTime: 0,
      businessContext: {
        relevantServices: [],
        suggestedActions: ['human_review'],
        urgencyLevel: 'low',
        requiresHumanReview: true,
        contextualInsights: ['Arquivo requer an√°lise manual']
      }
    }
  }

  private async combineAnalyses(
    textIntent: Intent,
    analyses: MultiModalAnalysis[],
    context: ConversationContext
  ): Promise<MultiModalIntentResult> {
    
    // Combinar entidades de todas as fontes
    const allEntities = [
      ...textIntent.entities,
      ...analyses.flatMap(a => a.entities)
    ]
    const enhancedEntities = this.helpers.combineEntities(allEntities as any[])

    // Combinar contextos de neg√≥cio
    const businessContexts = analyses
      .map(a => a.businessContext)
      .filter(Boolean) as any[]
    const combinedBusinessContext = this.helpers.combineBusinessContext(businessContexts)

    // Calcular confian√ßa combinada
    const analysisConfidences = analyses.map(a => a.confidence)
    const avgAnalysisConfidence = analysisConfidences.length > 0 ? 
      analysisConfidences.reduce((sum, conf) => sum + conf, 0) / analysisConfidences.length : 0
    
    const enhancedConfidence = (textIntent.confidence + avgAnalysisConfidence) / 2

    // Determinar se requer revis√£o humana
    const requiresHumanReview = 
      combinedBusinessContext.requiresHumanReview ||
      analyses.some(a => a.confidence < 0.7) ||
      analyses.some(a => a.warnings && a.warnings.length > 0) ||
      enhancedConfidence < 0.7

    // Determinar a√ß√£o recomendada
    const recommendedAction = this.helpers.determineRecommendedAction(
      textIntent,
      combinedBusinessContext,
      enhancedEntities
    )

    return {
      originalIntent: textIntent,
      multiModalEnhancement: analyses[0] || {
        contentId: 'combined',
        contentType: 'text',
        primaryAnalysis: 'An√°lise multi-modal combinada',
        entities: enhancedEntities,
        confidence: avgAnalysisConfidence,
        processingTime: 0
      },
      enhancedEntities,
      confidence: enhancedConfidence,
      recommendedAction,
      requiresHumanReview
    }
  }

  private determineContentType(mimetype: string): 'text' | 'audio' | 'image' | 'video' | 'document' {
    if (mimetype.startsWith('audio/')) return 'audio'
    if (mimetype.startsWith('image/')) return 'image'
    if (mimetype.startsWith('video/')) return 'video'
    if (mimetype.startsWith('text/') || 
        mimetype.includes('pdf') || 
        mimetype.includes('document') ||
        mimetype.includes('word')) return 'document'
    
    return 'document' // fallback
  }

  private formatFileSize(bytes: number): string {
    if (bytes === 0) return '0 Bytes'
    
    const k = 1024
    const sizes = ['Bytes', 'KB', 'MB', 'GB']
    const i = Math.floor(Math.log(bytes) / Math.log(k))
    
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i]
  }
}

export default WhatsAppMultiModalService 