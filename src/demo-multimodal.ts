import { MultiModalHelpers } from './services/multimodal-helpers.service'
import { MultiModalContent, MultiModalAnalysis } from './types/multimodal.types'
import { ConversationContext } from './types/ai.types'
import { AdvancedIntentRecognitionService } from './services/advanced-intent-recognition.service'

/**
 * Demonstra√ß√£o completa do sistema de processamento multi-modal
 */
async function demonstrateMultiModalProcessing() {
  console.log('üé¨ ===== DEMONSTRA√á√ÉO SISTEMA MULTI-MODAL ===== üé¨\n')

  const helpers = new MultiModalHelpers()
  const intentService = new AdvancedIntentRecognitionService()

  // Contexto base para demonstra√ß√£o
  const context: ConversationContext = {
    sessionId: 'multimodal_demo',
    userId: 'demo_user',
    tenantId: 'beauty_salon',
    phoneNumber: '+5511999888777',
    conversationHistory: [],
    lastInteraction: new Date()
  }

  console.log('üìã Contexto da conversa:')
  console.log(`   üë§ Usu√°rio: ${context.userId}`)
  console.log(`   üè¢ Tenant: ${context.tenantId}`)
  console.log(`   üìû Telefone: ${context.phoneNumber}\n`)

  // ===== TESTE 1: PROCESSAMENTO DE TEXTO =====
  console.log('üìù ===== TESTE 1: PROCESSAMENTO DE TEXTO =====')
  
  const textMessages = [
    'Ol√°! Gostaria de agendar um corte de cabelo para amanh√£ √†s 14h',
    'Preciso cancelar meu agendamento de hoje urgente!',
    'Qual o pre√ßo de uma escova e chapinha?',
    'Estou muito insatisfeita com o √∫ltimo atendimento!'
  ]

  for (let i = 0; i < textMessages.length; i++) {
    const message = textMessages[i]!
    console.log(`\n${i + 1}. üì± Mensagem: "${message}"`)

    const textContent: MultiModalContent = {
      id: `text_${i + 1}`,
      type: 'text',
      content: message,
      mimeType: 'text/plain',
      timestamp: new Date()
    }

    try {
      // An√°lise de intent tradicional
      const intent = await intentService.recognizeIntent(message, context)
      
      // An√°lise multi-modal
      const entities = await helpers.extractEntitiesFromText(message)
      const businessContext = await helpers.analyzeTextForBusiness(message, 'beauty')
      const emotionalAnalysis = await helpers.analyzeTextEmotion(message)

      console.log(`   üéØ Intent: ${intent.type} (${(intent.confidence * 100).toFixed(1)}%)`)
      console.log(`   üòä Emo√ß√£o: ${emotionalAnalysis.tone} (${(emotionalAnalysis.confidence * 100).toFixed(1)}%)`)
      console.log(`   üìä Sentimento: ${emotionalAnalysis.sentimentScore.toFixed(2)}`)
      console.log(`   üîß A√ß√µes sugeridas: ${businessContext.suggestedActions.join(', ')}`)
      console.log(`   ‚ö†Ô∏è  Urg√™ncia: ${businessContext.urgencyLevel}`)
      console.log(`   üë• Requer humano: ${businessContext.requiresHumanReview ? 'Sim' : 'N√£o'}`)
      
      if (entities.length > 0) {
        console.log(`   üè∑Ô∏è  Entidades: ${entities.map(e => `${e.type}:${e.value}`).join(', ')}`)
      }

    } catch (error) {
      console.log(`   ‚ùå Erro: ${error}`)
    }
  }

  // ===== TESTE 2: SIMULA√á√ÉO DE PROCESSAMENTO DE √ÅUDIO =====
  console.log('\n\nüéµ ===== TESTE 2: PROCESSAMENTO DE √ÅUDIO =====')

  const audioScenarios = [
    {
      id: 'audio_1',
      description: 'Cliente feliz agendando',
      simulatedTranscription: 'Oi meninas! Tudo bem? Queria agendar um corte e uma cor para sexta feira √†s tr√™s da tarde se poss√≠vel. Obrigada!'
    },
    {
      id: 'audio_2', 
      description: 'Cliente urgente',
      simulatedTranscription: 'Al√¥? Preciso cancelar meu hor√°rio de hoje porque teve uma emerg√™ncia aqui em casa. √â poss√≠vel remarcar para outro dia?'
    },
    {
      id: 'audio_3',
      description: 'Cliente insatisfeita',
      simulatedTranscription: 'Estou muito chateada com o atendimento de ontem. A cor do cabelo ficou completamente diferente do que eu pedi!'
    }
  ]

  for (const scenario of audioScenarios) {
    console.log(`\nüéß ${scenario.description}`)
    console.log(`   üìù Transcri√ß√£o: "${scenario.simulatedTranscription}"`)

    try {
      // Simular an√°lise de √°udio (usando transcri√ß√£o simulada)
      const entities = await helpers.extractEntitiesFromText(scenario.simulatedTranscription)
      const businessContext = await helpers.analyzeTextForBusiness(scenario.simulatedTranscription, 'beauty')
      const emotionalAnalysis = await helpers.analyzeTextEmotion(scenario.simulatedTranscription)

      console.log(`   üòä Tom emocional: ${emotionalAnalysis.tone}`)
      console.log(`   üìä Score sentimento: ${emotionalAnalysis.sentimentScore.toFixed(2)}`)
      console.log(`   üîß A√ß√£o recomendada: ${helpers.determineRecommendedAction(
        { type: 'service_inquiry', confidence: 0.8, entities: [] },
        businessContext,
        entities
      )}`)
      console.log(`   ‚ö†Ô∏è  Urg√™ncia: ${businessContext.urgencyLevel}`)

    } catch (error) {
      console.log(`   ‚ùå Erro na an√°lise: ${error}`)
    }
  }

  // ===== TESTE 3: SIMULA√á√ÉO DE PROCESSAMENTO DE IMAGEM =====
  console.log('\n\nüñºÔ∏è  ===== TESTE 3: PROCESSAMENTO DE IMAGEM =====')

  const imageScenarios = [
    {
      id: 'image_1',
      description: 'Foto de corte de cabelo desejado',
      simulatedAnalysis: 'Imagem mostra um corte de cabelo bob curto, loiro, bem definido e moderno. Aparenta ser um estilo profissional.'
    },
    {
      id: 'image_2',
      description: 'Foto de problema no cabelo',
      simulatedAnalysis: 'Imagem mostra cabelo com colora√ß√£o desigual, algumas mechas mais escuras que outras, aparenta ser um resultado insatisfat√≥rio.'
    },
    {
      id: 'image_3',
      description: 'Screenshot de hor√°rios',
      simulatedAnalysis: 'Captura de tela de um calend√°rio mostrando disponibilidade na quinta-feira √†s 15:30 e sexta-feira √†s 10:00.'
    }
  ]

  for (const scenario of imageScenarios) {
    console.log(`\nüì∏ ${scenario.description}`)
    console.log(`   üîç An√°lise visual: ${scenario.simulatedAnalysis}`)

    try {
      const businessContext = await helpers.analyzeTextForBusiness(scenario.simulatedAnalysis, 'beauty')
      const emotionalAnalysis = await helpers.analyzeTextEmotion(scenario.simulatedAnalysis)

      console.log(`   üíº Contexto: ${businessContext.contextualInsights.join(', ')}`)
      console.log(`   üîß Servi√ßos relevantes: ${businessContext.relevantServices.join(', ')}`)
      console.log(`   üòä Tom detectado: ${emotionalAnalysis.tone}`)

    } catch (error) {
      console.log(`   ‚ùå Erro na an√°lise: ${error}`)
    }
  }

  // ===== TESTE 4: COMBINA√á√ÉO MULTI-MODAL =====
  console.log('\n\nüîÄ ===== TESTE 4: COMBINA√á√ÉO MULTI-MODAL =====')

  const combinedScenario = {
    text: 'Olha s√≥ como eu quero que fique meu cabelo',
    imageDescription: 'Foto de um corte bob moderno com franja lateral',
    audioTranscription: 'Queria agendar para quinta feira de manh√£ se poss√≠vel'
  }

  console.log('üì± Cen√°rio combinado:')
  console.log(`   üí¨ Texto: "${combinedScenario.text}"`)
  console.log(`   üñºÔ∏è  Imagem: ${combinedScenario.imageDescription}`)
  console.log(`   üéµ √Åudio: "${combinedScenario.audioTranscription}"`)

  try {
    // Analisar cada modalidade
    const textAnalysis = await helpers.analyzeTextForBusiness(combinedScenario.text, 'beauty')
    const imageAnalysis = await helpers.analyzeTextForBusiness(combinedScenario.imageDescription, 'beauty')
    const audioAnalysis = await helpers.analyzeTextForBusiness(combinedScenario.audioTranscription, 'beauty')

    // Combinar an√°lises
    const combinedContext = helpers.combineBusinessContext([textAnalysis, imageAnalysis, audioAnalysis])

    console.log('\nüîÑ An√°lise combinada:')
    console.log(`   üîß A√ß√µes sugeridas: ${combinedContext.suggestedActions.join(', ')}`)
    console.log(`   üíº Servi√ßos relevantes: ${combinedContext.relevantServices.join(', ')}`)
    console.log(`   ‚ö†Ô∏è  N√≠vel de urg√™ncia: ${combinedContext.urgencyLevel}`)
    console.log(`   üë• Requer revis√£o humana: ${combinedContext.requiresHumanReview ? 'Sim' : 'N√£o'}`)
    console.log(`   üí° Insights: ${combinedContext.contextualInsights.join(', ')}`)

  } catch (error) {
    console.log(`   ‚ùå Erro na an√°lise combinada: ${error}`)
  }

  // ===== TESTE 5: CAPACIDADES DO SISTEMA =====
  console.log('\n\n‚öôÔ∏è  ===== TESTE 5: CAPACIDADES DO SISTEMA =====')

  console.log('üìã Formatos suportados:')
  console.log('   üéµ √Åudio: wav, mp3, m4a, ogg')
  console.log('   üñºÔ∏è  Imagem: jpeg, png, gif, webp')
  console.log('   üé• V√≠deo: mp4, mov, avi')
  console.log('   üìÑ Documento: pdf, txt, doc')

  console.log('\nüîß Funcionalidades dispon√≠veis:')
  console.log('   ‚úÖ Transcri√ß√£o de √°udio')
  console.log('   ‚úÖ An√°lise visual de imagens')
  console.log('   ‚úÖ OCR (extra√ß√£o de texto)')
  console.log('   ‚úÖ Detec√ß√£o de emo√ß√£o')
  console.log('   ‚úÖ An√°lise de contexto de neg√≥cio')
  console.log('   ‚úÖ Extra√ß√£o de entidades')
  console.log('   ‚úÖ Combina√ß√£o multi-modal')
  console.log('   ‚úÖ Cache inteligente')
  console.log('   ‚úÖ M√©tricas de performance')

  console.log('\nüìä Limites de arquivo:')
  console.log('   üéµ √Åudio: 25MB')
  console.log('   üñºÔ∏è  Imagem: 20MB')
  console.log('   üé• V√≠deo: 100MB')
  console.log('   üìÑ Documento: 50MB')

  // ===== TESTE 6: DETEC√á√ÉO DE IDIOMA =====
  console.log('\n\nüåç ===== TESTE 6: DETEC√á√ÉO DE IDIOMA =====')

  const textSamples = [
    'Ol√°, gostaria de agendar um hor√°rio',
    'Hello, I would like to schedule an appointment',
    'Hola, me gustar√≠a programar una cita',
    'Bonjour, je voudrais prendre un rendez-vous'
  ]

  for (const text of textSamples) {
    const detectedLang = helpers.detectLanguageFallback(text)
    console.log(`   "${text}" ‚Üí ${detectedLang}`)
  }

  console.log('\n‚úÖ ===== DEMONSTRA√á√ÉO CONCLU√çDA ===== ‚úÖ')
  console.log('üéâ Sistema multi-modal funcionando corretamente!')
  console.log('üìä Todas as funcionalidades testadas com sucesso')
}

// Executar demonstra√ß√£o
if (require.main === module) {
  demonstrateMultiModalProcessing()
    .then(() => {
      console.log('\nüèÅ Demonstra√ß√£o finalizada!')
      process.exit(0)
    })
    .catch((error) => {
      console.error('\n‚ùå Erro na demonstra√ß√£o:', error)
      process.exit(1)
    })
}

export { demonstrateMultiModalProcessing } 